{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4787353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "import nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6c6f139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  category\n",
      "0  when modi promised â€œminimum government maximum...      -1.0\n",
      "1  talk all the nonsense and continue all the dra...       0.0\n",
      "2  what did just say vote for modi  welcome bjp t...       1.0\n",
      "3  asking his supporters prefix chowkidar their n...       1.0\n",
      "4  answer who among these the most powerful world...       1.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Twitter_Data.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5282322",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sruja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "data[\"cleaned_text\"] = data[\"clean_text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498ea4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentence_length'] = data['cleaned_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19e0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cleaned_text']\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3336552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_encoded = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_encoded, padding='pre')\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = X_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccf5c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde3f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60bd7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6176ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2038/2038 [==============================] - 333s 163ms/step - loss: 0.1393 - accuracy: 0.9514\n",
      "Epoch 2/10\n",
      "2038/2038 [==============================] - 281s 138ms/step - loss: 0.1066 - accuracy: 0.9622\n",
      "Epoch 3/10\n",
      "2038/2038 [==============================] - 414s 203ms/step - loss: 0.0862 - accuracy: 0.9697\n",
      "Epoch 4/10\n",
      "2038/2038 [==============================] - 486s 238ms/step - loss: 0.0686 - accuracy: 0.9756\n",
      "Epoch 5/10\n",
      "2038/2038 [==============================] - 295s 145ms/step - loss: 0.0559 - accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "2038/2038 [==============================] - 314s 154ms/step - loss: 0.0476 - accuracy: 0.9832\n",
      "Epoch 7/10\n",
      "2038/2038 [==============================] - 253s 124ms/step - loss: 0.0375 - accuracy: 0.9868\n",
      "Epoch 8/10\n",
      "2038/2038 [==============================] - 263s 129ms/step - loss: 0.0331 - accuracy: 0.9887\n",
      "Epoch 9/10\n",
      "2038/2038 [==============================] - 277s 136ms/step - loss: 0.0287 - accuracy: 0.9899\n",
      "Epoch 10/10\n",
      "2038/2038 [==============================] - 275s 135ms/step - loss: 0.0255 - accuracy: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28884cfa8e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "091fc51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019/1019 [==============================] - 8s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1222213",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_normalized = pd.DataFrame(y_pred).applymap(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c96bc4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.73      7179\n",
      "           1       0.84      0.83      0.83     11034\n",
      "           2       0.84      0.85      0.84     14383\n",
      "\n",
      "    accuracy                           0.81     32596\n",
      "   macro avg       0.80      0.80      0.80     32596\n",
      "weighted avg       0.81      0.81      0.81     32596\n",
      "\n",
      "Accuracy: 0.8142716897778869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_test.values.argmax(axis=1), y_pred_normalized.values.argmax(axis=1)))\n",
    "accuracy = accuracy_score(y_test.values.argmax(axis=1), y_pred_normalized.values.argmax(axis=1))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
